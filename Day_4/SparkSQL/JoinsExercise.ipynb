{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKOUpoTJSrrg"
      },
      "source": [
        "## Joins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yuEvSROVSrrk",
        "outputId": "be2978d8-982a-4a77-deed-5807cff22fbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/09/04 15:17:49 WARN Utils: Your hostname, anujs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.68 instead (on interface en0)\n",
            "23/09/04 15:17:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/09/04 15:17:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "23/09/04 15:17:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/09/04 15:18:06 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"day3\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1BsRJJzSrrn"
      },
      "source": [
        "\n",
        "Question: You are given two DataFrames: employees_df and departments_df, which contain information about employees and their respective departments. The schema for the DataFrames is as follows:\n",
        "\n",
        "employees_df schema:\n",
        "|-- employee_id: integer (nullable = true)\n",
        "|-- employee_name: string (nullable = true)\n",
        "|-- department_id: integer (nullable = true)\n",
        "\n",
        "departments_df schema:\n",
        "\n",
        "|-- department_id: integer (nullable = true)\n",
        "|-- department_name: string (nullable = true)\n",
        "\n",
        "Employees DataFrame:\n",
        "                                                                                \n",
        "+-----------+-------------+-------------+\n",
        "|employee_id|employee_name|department_id|\n",
        "+-----------+-------------+-------------+\n",
        "|1          |Pallavi mam  |101          |\n",
        "|2          |Bob          |102          |\n",
        "|3          |Cathy        |101          |\n",
        "|4          |David        |103          |\n",
        "|5          |Amrit Sir    |104          |\n",
        "|6          |Alice        |null         |\n",
        "|7          |Eva          |null         |\n",
        "|8          |Frank        |110          |\n",
        "|9          |Grace        |109          |\n",
        "|10         |Henry        |null         |\n",
        "+-----------+-------------+-------------+\n",
        "\n",
        "\n",
        "\n",
        "Departments DataFrame:\n",
        "+-------------+------------------------+\n",
        "|department_id|department_name         |\n",
        "+-------------+------------------------+\n",
        "|101          |HR                      |\n",
        "|102          |Engineering             |\n",
        "|103          |Finance                 |\n",
        "|104          |Marketing               |\n",
        "|105          |Operations              |\n",
        "|106          |null                    |\n",
        "|107          |Operations              |\n",
        "|108          |Production              |\n",
        "|null         |Finance                 |\n",
        "|110          |Research and Development|\n",
        "+-------------+----------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VOULO8eWSrro",
        "outputId": "c971652b-357e-4f87-dab2-f3ce9d18f5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Employee Dataframe\n",
            "root\n",
            " |-- Employee_Id: integer (nullable = true)\n",
            " |-- Employee_name: string (nullable = true)\n",
            " |-- department_id: integer (nullable = true)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+-------------+\n",
            "|Employee_Id|Employee_name|department_id|\n",
            "+-----------+-------------+-------------+\n",
            "|          1|  Pallavi mam|          101|\n",
            "|          2|          Bob|          102|\n",
            "|          3|        Cathy|          101|\n",
            "|          4|        David|          103|\n",
            "|          5|    Amrit Sir|          104|\n",
            "|          6|        Alice|         null|\n",
            "|          7|          Eva|         null|\n",
            "|          8|        Frank|          110|\n",
            "|          9|        Grace|          109|\n",
            "|         10|        Henry|         null|\n",
            "+-----------+-------------+-------------+\n",
            "\n",
            "Department Dataframe\n",
            "root\n",
            " |-- department_id: integer (nullable = true)\n",
            " |-- department_name: string (nullable = true)\n",
            "\n",
            "+-------------+------------------------+\n",
            "|department_id|department_name         |\n",
            "+-------------+------------------------+\n",
            "|101          |Hr                      |\n",
            "|102          |Engineering             |\n",
            "|103          |Finance                 |\n",
            "|104          |Marketing               |\n",
            "|105          |Operation               |\n",
            "|106          |null                    |\n",
            "|107          |Operations              |\n",
            "|108          |Production              |\n",
            "|null         |Finance                 |\n",
            "|110          |Research and Development|\n",
            "+-------------+------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Importing necessary library \n",
        "from pyspark.sql.types import StructField,StructType,StringType,IntegerType\n",
        "\n",
        "employee_data = [(1,'Pallavi mam',101),\n",
        "                 (2,'Bob',102),\n",
        "                 (3,'Cathy',101),\n",
        "                 (4,'David',103),\n",
        "                 (5,'Amrit Sir',104),\n",
        "                 (6,'Alice',None),\n",
        "                 (7,'Eva',None),\n",
        "                 (8,'Frank',110),\n",
        "                 (9,'Grace',109),\n",
        "                 (10,'Henry',None)]\n",
        "\n",
        "Department_Data = [(101,'Hr'),\n",
        "                   (102,'Engineering'),\n",
        "                   (103,'Finance'),\n",
        "                   (104,'Marketing'),\n",
        "                   (105,'Operation'),\n",
        "                   (106,None),\n",
        "                   (107,'Operations'),\n",
        "                   (108,'Production'),\n",
        "                   (None,'Finance'),\n",
        "                   (110,'Research and Development')]\n",
        "\n",
        "employee_schema = StructType([\n",
        "    StructField(\"Employee_Id\",IntegerType(),True),\n",
        "    StructField(\"Employee_name\",StringType(),True),\n",
        "    StructField(\"department_id\",IntegerType(),True)\n",
        "])\n",
        "\n",
        "department_schema = StructType([\n",
        "    StructField(\"department_id\",IntegerType(),True),\n",
        "    StructField(\"department_name\",StringType(),True)\n",
        "])\n",
        "\n",
        "employee_df  = spark.createDataFrame(data=employee_data,schema=employee_schema)\n",
        "department_df = spark.createDataFrame(data=Department_Data, schema=department_schema)\n",
        "\n",
        "print(\"Employee Dataframe\")\n",
        "employee_df.printSchema()\n",
        "employee_df.show()\n",
        "\n",
        "print(\"Department Dataframe\")\n",
        "department_df.printSchema()\n",
        "department_df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-AGTer7Srrp"
      },
      "source": [
        "### Join Expressions\n",
        "\n",
        "Question: How can you combine the employees_df and departments_df DataFrames based on the common \"department_id\" column to get a combined DataFrame with employee names and their respective department names?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s8Hx7RRkSrrp",
        "outputId": "3a9af3d7-12a4-4d86-e116-8552c002c054"
      },
      "outputs": [],
      "source": [
        "department_df.createOrReplaceTempView(\"department\")\n",
        "employee_df.createOrReplaceTempView(\"employee\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----------+-------------+--------------------+\n",
            "|department_id|employee_id|employee_name|     department_name|\n",
            "+-------------+-----------+-------------+--------------------+\n",
            "|          101|          1|  Pallavi mam|                  Hr|\n",
            "|          101|          3|        Cathy|                  Hr|\n",
            "|          102|          2|          Bob|         Engineering|\n",
            "|          103|          4|        David|             Finance|\n",
            "|          104|          5|    Amrit Sir|           Marketing|\n",
            "|          110|          8|        Frank|Research and Deve...|\n",
            "+-------------+-----------+-------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "join_exp = spark.sql(\"\"\"\n",
        "                    select d.department_id, e.employee_id, e.employee_name, d.department_name\n",
        "                    from department d\n",
        "                    join employee e\n",
        "                    on d.department_id = e.department_id\n",
        "\"\"\")\n",
        "                     \n",
        "join_exp.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy7PeX3oSrrp"
      },
      "source": [
        "### Inner Joins\n",
        "\n",
        "Question: How can you retrieve employee names and their respective department names for employees belonging to the \"Engineering\" department?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rsmLDPaASrrp",
        "outputId": "16bb5415-ee7e-422f-8103-732066bc2f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+\n",
            "|employee_name|department_name|\n",
            "+-------------+---------------+\n",
            "|          Bob|    Engineering|\n",
            "+-------------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "inner_join_sql = spark.sql(\"\"\"\n",
        "                            select e.employee_name, d.department_name\n",
        "                           from department d\n",
        "                           join employee e\n",
        "                           on e.department_id = d.department_id\n",
        "                           where d.department_name = 'Engineering' \n",
        " \"\"\")\n",
        "\n",
        "inner_join_sql.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e3-Z98rSrrq"
      },
      "source": [
        "### Outer Joins\n",
        "\n",
        "Question: Retrieve a DataFrame that contains all employees along with their department names. If an employee doesn't have a department assigned, display \"No Department\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h7x9gxDsSrrq",
        "outputId": "80b4d9fe-de4a-4a6c-cb93-c1e6d6631b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+--------------------+\n",
            "|employee_name|     department_name|\n",
            "+-------------+--------------------+\n",
            "|        Alice|       no department|\n",
            "|          Eva|       no department|\n",
            "|        Henry|       no department|\n",
            "|  no Employee|             Finance|\n",
            "|  Pallavi mam|                  Hr|\n",
            "|        Cathy|                  Hr|\n",
            "|          Bob|         Engineering|\n",
            "|        David|             Finance|\n",
            "|    Amrit Sir|           Marketing|\n",
            "|  no Employee|           Operation|\n",
            "|  no Employee|       no department|\n",
            "|  no Employee|          Operations|\n",
            "|  no Employee|          Production|\n",
            "|        Grace|       no department|\n",
            "|        Frank|Research and Deve...|\n",
            "+-------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "outer_join_sql = spark.sql(\"\"\"\n",
        "                            select coalesce(e.employee_name, 'no Employee') as employee_name, \n",
        "                                   coalesce(d.department_name, 'no department') as department_name\n",
        "                           from employee e\n",
        "                           full outer join department d\n",
        "                           on d.department_id = e.department_id\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "outer_join_sql.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfHrBAwPSrrq"
      },
      "source": [
        "### Left Outer Joins\n",
        "\n",
        "Question: List all employees along with their department names. If an employee doesn't have a department assigned, display \"No Department\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IVuvSkFZSrrq",
        "outputId": "64e15ec7-43f6-4beb-f984-15e2a03147fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+--------------------+\n",
            "|employee_name|     department_name|\n",
            "+-------------+--------------------+\n",
            "|  Pallavi mam|                  Hr|\n",
            "|          Bob|         Engineering|\n",
            "|        Cathy|                  Hr|\n",
            "|        David|             Finance|\n",
            "|    Amrit Sir|           Marketing|\n",
            "|        Alice|       no department|\n",
            "|          Eva|       no department|\n",
            "|        Frank|Research and Deve...|\n",
            "|        Henry|       no department|\n",
            "|        Grace|       no department|\n",
            "+-------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "left_outer_join_sql = spark.sql(\"\"\"\n",
        "                                    select e.employee_name,\n",
        "                                            coalesce(d.department_name, 'no department') as department_name\n",
        "                                    from employee e\n",
        "                                    left outer join department d\n",
        "                                    on e.department_id = d.department_id       \n",
        "\n",
        "                                \"\"\")\n",
        "\n",
        "left_outer_join_sql.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qie43J-ESrrr"
      },
      "source": [
        "### Right Outer Joins\n",
        "\n",
        "Question: Display a list of departments along with employee names. If a department has no employees, display \"No Employees\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gt0OksKnSrrr",
        "outputId": "97110655-4d24-4de5-b502-c040e15f632a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+\n",
            "|     department_name|employee_name|\n",
            "+--------------------+-------------+\n",
            "|                  Hr|        Cathy|\n",
            "|                  Hr|  Pallavi mam|\n",
            "|         Engineering|          Bob|\n",
            "|             Finance|        David|\n",
            "|           Operation|  No employee|\n",
            "|           Marketing|    Amrit Sir|\n",
            "|                null|  No employee|\n",
            "|          Operations|  No employee|\n",
            "|          Production|  No employee|\n",
            "|             Finance|  No employee|\n",
            "|Research and Deve...|        Frank|\n",
            "+--------------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "right_outer_join_sql = spark.sql(\"\"\"\n",
        "                                select d.department_name as department_name,\n",
        "                                       coalesce(e.employee_name,'No employee') as employee_name\n",
        "                                 from employee e\n",
        "                                 right outer join department d\n",
        "                                 on e.department_id = d.department_id\n",
        "                                \"\"\")\n",
        "\n",
        "right_outer_join_sql.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ3hFQ1ZSrrr"
      },
      "source": [
        "### Left Semi Joins\n",
        "\n",
        "Question: Retrieve a DataFrame that includes employee names for departments that have employees.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZG4gNRqPSrrs",
        "outputId": "d72aeb8b-1e13-4e1a-82da-463f83964799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+\n",
            "|employee_name|\n",
            "+-------------+\n",
            "|  Pallavi mam|\n",
            "|        Cathy|\n",
            "|          Bob|\n",
            "|        David|\n",
            "|    Amrit Sir|\n",
            "|        Frank|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "left_semi_join_sql = spark.sql(\"\"\"\n",
        "                                select e.employee_name\n",
        "                               from employee e\n",
        "                               left semi join department d\n",
        "                               on e.department_id = d.department_id\n",
        "                                \n",
        "                               \"\"\" )\n",
        "\n",
        "left_semi_join_sql.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jstEtkSSSrrs"
      },
      "source": [
        "### Left Anti Joins\n",
        "\n",
        "Question: Find the employees who don't belong to any department."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yUwiRb33Srrs",
        "outputId": "06e5a481-ddd4-4c57-8688-1e83b7570d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+\n",
            "|employee_name|\n",
            "+-------------+\n",
            "|        Alice|\n",
            "|          Eva|\n",
            "|        Henry|\n",
            "|        Grace|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "left_anti_join_sql = spark.sql(\"\"\"\n",
        "                                select e.employee_name\n",
        "                               from employee e\n",
        "                               left anti join department d\n",
        "                               on e.department_id = d.department_id\n",
        "                                \n",
        "                               \"\"\" )\n",
        "\n",
        "left_anti_join_sql.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_4r9Qw4Srrs"
      },
      "source": [
        "### Cross (Cartesian) Joins\n",
        "\n",
        "Question: Create a DataFrame that contains all possible combinations of employees and departments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RCNCE2iESrrs",
        "outputId": "24f2b58b-da7d-4048-c76c-cd2b0eaeb3eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 46:============================================>           (15 + 4) / 19]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+-------------+-------------+--------------------+\n",
            "|Employee_Id|Employee_name|department_id|department_id|     department_name|\n",
            "+-----------+-------------+-------------+-------------+--------------------+\n",
            "|          1|  Pallavi mam|          101|          101|                  Hr|\n",
            "|          1|  Pallavi mam|          101|          102|         Engineering|\n",
            "|          1|  Pallavi mam|          101|          103|             Finance|\n",
            "|          1|  Pallavi mam|          101|          104|           Marketing|\n",
            "|          1|  Pallavi mam|          101|          105|           Operation|\n",
            "|          1|  Pallavi mam|          101|          106|                null|\n",
            "|          1|  Pallavi mam|          101|          107|          Operations|\n",
            "|          1|  Pallavi mam|          101|          108|          Production|\n",
            "|          1|  Pallavi mam|          101|         null|             Finance|\n",
            "|          1|  Pallavi mam|          101|          110|Research and Deve...|\n",
            "|          2|          Bob|          102|          101|                  Hr|\n",
            "|          2|          Bob|          102|          102|         Engineering|\n",
            "|          2|          Bob|          102|          103|             Finance|\n",
            "|          2|          Bob|          102|          104|           Marketing|\n",
            "|          2|          Bob|          102|          105|           Operation|\n",
            "|          2|          Bob|          102|          106|                null|\n",
            "|          2|          Bob|          102|          107|          Operations|\n",
            "|          2|          Bob|          102|          108|          Production|\n",
            "|          2|          Bob|          102|         null|             Finance|\n",
            "|          2|          Bob|          102|          110|Research and Deve...|\n",
            "+-----------+-------------+-------------+-------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "cross_join_sql = spark.sql(\"\"\"\n",
        "                            select * \n",
        "                           from employee\n",
        "                           cross join department\n",
        "\"\"\")\n",
        "                           \n",
        "cross_join_sql.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGKNWgSmSrrt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
